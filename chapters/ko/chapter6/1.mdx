# 단원 소개[[introduction]]

<CourseFloatingBanner
    chapter={6}
    classNames="absolute z-10 right-0 top-0"
/>

[Chapter 3](/course/chapter3)에서는 주어진 작업에 모델을 미세 조정하는 방법을 살펴보았습니다. 이 때, 모델이 사전 학습된 것과 동일한 토크나이저를 사용합니다. 그러나 모델을 처음부터 학습하려면 어떻게 해야 할까요? 이러한 경우 다른 도메인이나 언어의 말뭉치에서 사전 학습된 토크나이저를 사용하는 것은 일반적으로 최적이 아닙니다. 예를 들어, 일본어 텍스트에 대해 영어 말뭉치로 학습된 토크나이저를 사용하는 것은 두 언어 간에 공백과 구두점 사용이 매우 다르기 때문에 성능 저하를 가져올 것입니다.

이 장에서는 텍스트 말뭉치로부터 새로운 토크나이저를 학습시켜 언어 모델을 사전 학습할 수 있는 방법을 배우게 될 것입니다. 이 모든 것은 [🤗 Tokenizers](https://github.com/huggingface/tokenizers) 라이브러리의 도움을 받아 진행됩니다. 이 라이브러리는 [🤗 Transformers](https://github.com/huggingface/transformers) 라이브러리에서 "fast" tokenizer를 제공합니다. 이 라이브러리가 제공하는 기능을 자세히 살펴보고 fast tokenizer가 "slow" 버전과 어떻게 다른지 탐구할 것입니다.

다룰 주제는 다음과 같습니다:

* 새로운 말뭉치에서 주어진 체크포인트와 유사한 새로운 토크나이저를 학습하는 방법
* fast tokenizer의 특별한 기능
* 현재 자연어 처리에서 사용되는 세 가지 주요 서브워드 토크나이제이션 알고리즘의 차이점
* 🤗 Tokenizers 라이브러리를 사용하여 토크나이저를 처음부터 만들고 일부 데이터로 학습하는 방법

이 장에서 소개된 기술은 [Chapter 7](/course/chapter7/6)의 섹션에서 Python 소스 코드용 언어 모델을 만드는 부분에 대비할 것입니다. 먼저 토크나이저를 "학습"하는 것이 무엇을 의미하는지 살펴보겠습니다.